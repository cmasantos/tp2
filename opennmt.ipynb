{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pyonmttok\n",
    "import os\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code was adapted from the original source available here: https://github.com/OpenNMT/OpenNMT-tf/blob/36c737d1446e475e87b71519a6e7791b22a0f919/examples/serving/python/ende_client.py#L9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_dir = \"opennmt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['breeze through those minor but important activities that inevitably crop up during the day without switching context. quickly log calls, create tasks and events, and jot down notes, all from windows that open on the current page.',\n",
       " 'a visualization is commonly a chart or graph, such as a bar chart, donut chart, timeline, or heat map. it can also be data in tabular form, such as a comparison table or pivot table. every visualization has an underlying query, which is how analytics retrieves information from the source data.',\n",
       " 'add merge fields to a template or email:',\n",
       " 'to use quick text in the email global action, you must be on a record page. for example, if you’re viewing a list view and open the email global action, quick text doesn’t work.',\n",
       " 'a trigger is a set of apex code that fires at a particular time in the life cycle of a record. you can add apex triggers to comments in ideas to better manage ideas in your community.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the data set\n",
    "text_file = \"./train.txt\"\n",
    "\n",
    "with open(text_file, encoding=\"utf-8\") as file:\n",
    "    lines = file.read().split(\"\\n\")\n",
    "\n",
    "orginal_text_pairs = [(line.split(\"\\t\")) for line in lines] \n",
    "en = [pair[0] for pair in orginal_text_pairs]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "imported = tf.saved_model.load(export_dir)\n",
    "translate_fn = imported.signatures[\"serving_default\"]\n",
    "sp_model_path = os.path.join(export_dir, \"assets.extra\", \"wmtende.model\")\n",
    "tokenizer = pyonmttok.Tokenizer(\"none\", sp_model_path=sp_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(texts):\n",
    "        all_tokens = []\n",
    "        lengths = []\n",
    "        max_length = 0\n",
    "        for text in texts: \n",
    "            tokens, _ = tokenizer.tokenize(text)\n",
    "            length = len(tokens)\n",
    "            all_tokens.append(tokens)\n",
    "            lengths.append(length)\n",
    "            max_length = max(max_length, length) \n",
    "        \n",
    "        for tokens, length in zip(all_tokens, lengths):\n",
    "            if length < max_length:\n",
    "                tokens += [\"\"] * (max_length - length) \n",
    "\n",
    "        inputs = {\n",
    "            \"tokens\": tf.constant(all_tokens, dtype=tf.string),\n",
    "            \"length\": tf.constant(lengths, dtype=tf.int32),\n",
    "        }\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(outputs):\n",
    "    texts = []\n",
    "    for tokens, length in zip(outputs[\"tokens\"].numpy(), outputs[\"length\"].numpy()):\n",
    "        tokens = tokens[0][: length[0]].tolist()\n",
    "        texts.append(tokenizer.detokenize(tokens))\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(texts):\n",
    "        \"\"\"Translates a batch of texts.\"\"\"\n",
    "        inputs = preprocess(texts)\n",
    "        #print(inputs)\n",
    "        outputs = translate_fn(**inputs)\n",
    "        return postprocess(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Wenn ein neuer Benutzer nicht kooperativ ist', 'Wann ist es soweit?', 'Woher kommen Sie?']\n"
     ]
    }
   ],
   "source": [
    "input = \"If a New User Isn't Being Copied to the Linked Organization\" \n",
    "#input = \"hi how are you? im from portugal and im doing somee school work.\"\n",
    "output = translate([input, \"what time is it?\", \"where are you from?\"])\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tfgpu-clone')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9517802f9e486875bd1a90cb9316150f9c80975204a62a359dc8ac0c901cd1ea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
