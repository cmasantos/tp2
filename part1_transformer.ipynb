{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFydYD8rLnnE"
      },
      "source": [
        "Machine Translation - English to German"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "DPQTZko6LMsF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.9.1\n"
          ]
        }
      ],
      "source": [
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "try:\n",
        "    # %tensorflow_version only exists in Colab.\n",
        "    %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass\n",
        "# TensorFlow ≥2.0 is required\n",
        "import tensorflow as tf\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "print(tf.__version__)\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "\n",
        "# Ignore useless warnings (see SciPy issue #5998)\n",
        "import warnings\n",
        "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")\n",
        "\n",
        "\n",
        "import random\n",
        "\n",
        "import tensorflow as tf\n",
        "import string\n",
        "import re \n",
        "from keras import layers\n",
        "import io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "#input_text_file_path = \"./preprocessed_dataset_for_dev.txt\"\n",
        "input_text_file_path = \"./preprocessed_dataset_for_train.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "xYhzQXWdMJjs"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('the bookmarked feed shows the posts that you have bookmarked. the bookmarked feed offers easy access to useful posts.', '[start] im feed mit lesezeichen werden alle post angezeigt, die sie mit einem lesezeichen versehen haben. der feed \"mit lesezeichen\" bietet ihnen schnellen zugriff auf nützliche posts. [end]')\n"
          ]
        }
      ],
      "source": [
        "with open(input_text_file_path, encoding='utf-8') as f:\n",
        "    lines = f.read().split(\"\\n\")[:-1]\n",
        "\n",
        "text_pairs = []\n",
        "\n",
        "for line in lines:\n",
        "    english, port = line.split(\"\\t\")\n",
        "    port = \"[start] \" + port + \" [end]\"\n",
        "    text_pairs.append((english, port))\n",
        "\n",
        "print(text_pairs[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Terv66lhM4X5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "len(text_pairs) -> 100611\n",
            "15% for validation -> 15091\n",
            "70% for train -> 70429\n"
          ]
        }
      ],
      "source": [
        "random.shuffle(text_pairs) #1. mistura todos os pairs\n",
        "\n",
        "print(\"len(text_pairs) ->\", len(text_pairs))\n",
        "\n",
        "num_val_samples = int(0.15 * len(text_pairs))\n",
        "print(\"15% for validation ->\", num_val_samples)\n",
        "\n",
        "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
        "print(\"70% for train ->\", num_train_samples)\n",
        "\n",
        "train_pairs = text_pairs[:num_train_samples] #escolhe os primeiros 70% (shuffled) para treino\n",
        "val_pairs = text_pairs[num_train_samples:num_train_samples + num_val_samples] #mais 15% para validação\n",
        "test_pairs = text_pairs[num_train_samples + num_val_samples:] #mais 15 para teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "X8pce-80NB_u"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "treino:  70429\n",
            "validação:  15091\n",
            "teste:  15091\n"
          ]
        }
      ],
      "source": [
        "print(\"treino: \",    len(train_pairs))\n",
        "print(\"validação: \", len(val_pairs  ))\n",
        "print(\"teste: \",     len(test_pairs ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "hX1CnrGxPax4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('the maximum number of digits in a numeric value, or the length of a text value. for numeric values: includes all numbers to the left and to the right of the decimal point (but excludes the decimal point character). value must be from 1 to 16. for text values: value defaults to 255 characters, and must be from 1 to 32,000 characters.', '[start] die maximale anzahl von dezimalstellen in einem numerischen wert oder die länge eines textwerts. bei numerischen werten: umfasst alle dezimalstellen links und rechts vom dezimaltrennzeichen (jedoch ohne das dezimaltrennzeichen selbst). der wert muss zwischen 1 und 16 liegen. für textwerte: der wert beträgt standardmäßig 255 zeichen und muss zwischen 1 und 32.000 zeichen liegen. [end]')\n",
            "the maximum number of digits in a numeric value, or the length of a text value. for numeric values: includes all numbers to the left and to the right of the decimal point (but excludes the decimal point character). value must be from 1 to 16. for text values: value defaults to 255 characters, and must be from 1 to 32,000 characters.\n",
            "q\n"
          ]
        }
      ],
      "source": [
        "strip_chars = string.punctuation # !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
        "\n",
        "strip_chars = strip_chars.replace(\"[\", \"\") # para não perder o [start] e [end]\n",
        "strip_chars = strip_chars.replace(\"]\", \"\") #\n",
        "\n",
        "def custom_standardization(input_string):\n",
        "    lowercase = tf.strings.lower(input_string)\n",
        "    return tf.strings.regex_replace(\n",
        "        lowercase, f\"[{re.escape(strip_chars)}]\", \"\")\n",
        "\n",
        "vocab_size = 22000    # O modelo apneas vai conhecer 15000 palavras\n",
        "sequence_length = 25  # cada frase vai ter 20 palavrasg\n",
        "\n",
        "\n",
        "source_vectorization = layers.TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length\n",
        ")\n",
        "\n",
        "target_vectorization = layers.TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length + 1,\n",
        "    standardize=custom_standardization,\n",
        ")\n",
        "\n",
        "print(train_pairs[0])\n",
        "train_english_texts = [pair[0] for pair in train_pairs] \n",
        "print(train_english_texts[0])\n",
        "\n",
        "train_pt_texts = [pair[1] for pair in train_pairs] \n",
        "print(train_english_texts[1])\n",
        "\n",
        "source_vectorization.adapt(train_english_texts)\n",
        "#source_vectorization.adapt([pair[0] for pair in text_pairs] )\n",
        "target_vectorization.adapt(train_pt_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "xY0Eqvx_JRgH"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['', '[UNK]', 'the', 'to', 'a', 'and', 'in', 'you', 'for', 'your']"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "source_vectorization.get_vocabulary()[0:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "9EfEL9D9Jr2_"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['', '[UNK]', '[start]', '[end]', 'sie', 'die', 'der', 'und', 'in', 'für']"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "target_vectorization.get_vocabulary()[0:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EN embeddings has 400000 word vectors\n"
          ]
        }
      ],
      "source": [
        "glove50_file_path = \"./glove.6B.50d.embedding\"\n",
        "\n",
        "embeddings_index = {}\n",
        "\n",
        "with open(glove50_file_path, encoding=\"utf-8\") as gloveFile:\n",
        "    for line in gloveFile:\n",
        "        word, coefsAsString = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefsAsString, \"f\", sep=\" \")\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "print(f\"EN embeddings has {len(embeddings_index)} word vectors\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "embedding_matrix size: (22000, 50)\n",
            "[[ 0.68046999 -0.039263    0.30186    -0.17792     0.42962     0.032246\n",
            "  -0.41376001  0.13228001 -0.29846999 -0.085253    0.17117999  0.22419\n",
            "  -0.10046    -0.43652999  0.33418     0.67846     0.057204   -0.34448001\n",
            "  -0.42785001 -0.43274999  0.55962998  0.10032     0.18677001 -0.26853999\n",
            "   0.037334   -2.09319997  0.22171    -0.39868     0.20912001 -0.55725002\n",
            "   3.88260007  0.47466001 -0.95657998 -0.37788001  0.20869    -0.32752001\n",
            "   0.12751     0.088359    0.16350999 -0.21634001 -0.094375    0.018324\n",
            "   0.21048    -0.03088    -0.19722     0.082279   -0.09434    -0.073297\n",
            "  -0.064699   -0.26043999]\n",
            " [ 0.21705     0.46515    -0.46757001  0.10082     1.01349998  0.74844998\n",
            "  -0.53104001 -0.26256001  0.16812     0.13181999 -0.24909    -0.44185001\n",
            "  -0.21739     0.51003999  0.13448    -0.43141001 -0.03123     0.20674001\n",
            "  -0.78138    -0.20148    -0.097401    0.16088    -0.61835998 -0.18504\n",
            "  -0.12461    -2.25259995 -0.22321001  0.5043      0.32257     0.15312999\n",
            "   3.96359992 -0.71364999 -0.67012     0.28388     0.21738     0.14432999\n",
            "   0.25926     0.23434     0.42739999 -0.44451001  0.13812999  0.36973\n",
            "  -0.64288998  0.024142   -0.039315   -0.26036999  0.12017    -0.043782\n",
            "   0.41012999  0.1796    ]]\n"
          ]
        }
      ],
      "source": [
        "en_embeddings_dim = 50\n",
        "\n",
        "en_vocabulary = source_vectorization.get_vocabulary() \n",
        "\n",
        "word_index = dict(zip(en_vocabulary, range(len(en_vocabulary)))) # setting an \"id\" to head word \n",
        "\n",
        "embedding_matrix = np.zeros((vocab_size, en_embeddings_dim)) \n",
        "print(\"embedding_matrix size:\", embedding_matrix.shape)\n",
        "\n",
        "for word, i in word_index.items():\n",
        "    if(i < vocab_size):\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "\n",
        "    if(embedding_vector is not None):\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "\n",
        "print(embedding_matrix[3:5])\n",
        "\n",
        "en_embedding_layer = layers.Embedding(vocab_size, en_embeddings_dim, embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "yjNBmkmaQE1K"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "\n",
        "def format_dataset(eng, pt):\n",
        "    eng = source_vectorization(eng)\n",
        "    pt = target_vectorization(pt)\n",
        "    return ({\n",
        "        \"english\": eng,\n",
        "        \"portuguese\": pt[:, :-1],\n",
        "    }, pt[:, 1:])\n",
        "\n",
        "def make_dataset(pairs):\n",
        "    eng_texts, pt_texts = zip(*pairs)\n",
        "    eng_texts = list(eng_texts)\n",
        "    pt_texts = list(pt_texts)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, pt_texts))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.map(format_dataset, num_parallel_calls=4)\n",
        "    return dataset.shuffle(2048).prefetch(16).cache()\n",
        "\n",
        "train_ds = make_dataset(train_pairs)\n",
        "val_ds = make_dataset(val_pairs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "Ptr32zceQLUx"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "inputs['english'].shape: (32, 25)\n",
            "inputs['portuguese'].shape: (32, 25)\n",
            "targets.shape: (32, 25)\n",
            "tf.Tensor(\n",
            "[[   19     2   252    67     8     2    53   912    90     7    72     3\n",
            "    189   376     3    23   226     0     0     0     0     0     0     0\n",
            "      0]\n",
            " [   27     7   322     4 12038    55    18     4   221    55     2   221\n",
            "     55    97    54   162    30     2   623    37     0     0     0     0\n",
            "      0]\n",
            " [  157   238   226     5     2    15    49    67    16   226   243  1020\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0]\n",
            " [   16     2   418    62    23     7    14     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0]\n",
            " [   17  2391   254   294   985     3     4   363    86    26    13    96\n",
            "     45     3     2   363    14    48    40    44     6     2   363     0\n",
            "      0]\n",
            " [   24    51  1113   294   520   414     2    89  2737     2  1869    10\n",
            "    362   457   575     0     0     0     0     0     0     0     0     0\n",
            "      0]\n",
            " [    3   664   557    77   167    24   843    27   107   800    30     4\n",
            "     15    37   787     4    35    53    13   886     2  1199  5610    24\n",
            "    843]\n",
            " [  283   575    27     2   387    12     6  1631  1076     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0]\n",
            " [   46   227 12602  1214   520     4   561     3     2    21   137   528\n",
            "      3  1267   227   443    46   227     0     0     0     0     0     0\n",
            "      0]\n",
            " [13346     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0]\n",
            " [   78 12389     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0]\n",
            " [    3   262    24  1155    91    19    24   196   110     2    91    19\n",
            "     91   308     0     0     0     0     0     0     0     0     0     0\n",
            "      0]\n",
            " [   17   166   460  3515   225     2    80    10   173     3   152   457\n",
            "     23     6     2   173   457    23    22     0     0     0     0     0\n",
            "      0]\n",
            " [    2   123   509   564     4   404    10     2    34     6  2147   126\n",
            "     13   151    68     4   105  1022   102    34    20  1667    16     2\n",
            "   8232]\n",
            " [ 7604  1067    10     2  1399     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0]\n",
            " [  877    20     4   135    53    17     9    89    96  2284   300   154\n",
            "     40   877    20   586    17  2284   154    12   419   877    14    54\n",
            "    586]\n",
            " [   38     2   100    56   401     8     2   121   150    30     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0]\n",
            " [14172     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0]\n",
            " [    2   186   843    12  1918    36     2  2061   388   496     2    55\n",
            "     96  1912   155   163     2   843    12  1660   747     2    95   222\n",
            "    808]\n",
            " [11846   188   612    36   129   119     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0]\n",
            " [  510     2   736     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0]\n",
            " [  207    34     6     2  1387    20   562     2   114  1543     2  2293\n",
            "    766    17   486    12    78     0     0     0     0     0     0     0\n",
            "      0]\n",
            " [  668   201   252   291     6     2    46   106    92  2015    19   486\n",
            "      7    14   103   260     5  1540     2   381   201    77   846     5\n",
            "    116]\n",
            " [  427   102    35   948     3   214     2   752     8     9    35   579\n",
            "    538     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0]\n",
            " [  237     2    62     3   707    13    42   288     2    25     7  1974\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0]\n",
            " [  877     6    46   106   141   172     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0]\n",
            " [   75     8    25    19   117    75  1222     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0]\n",
            " [  110   430    19     4   278   365  1111     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0]\n",
            " [    2    39    48  2243    18     9   562   148   296     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0]\n",
            " [  355   235    22    36    71    60   425    16     2    23   122     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0]\n",
            " [  544     6    86  8301  1159    16  1289    44     5    37 13887   666\n",
            "    105   524   159    13     2    26    96    45  6933  1102    36     4\n",
            "     26]\n",
            " [13532     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0]], shape=(32, 25), dtype=int64)\n"
          ]
        }
      ],
      "source": [
        "for inputs, targets in train_ds.take(1):\n",
        "    print(f\"inputs['english'].shape: {inputs['english'].shape}\")\n",
        "    print(f\"inputs['portuguese'].shape: {inputs['portuguese'].shape}\")\n",
        "    print(f\"targets.shape: {targets.shape}\")\n",
        "    print(inputs['english'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "7r7M3lbPTCYx"
      },
      "outputs": [],
      "source": [
        "# Criação da classe que modela o Encoder \n",
        "\n",
        "# Na criação do objeto recebe \n",
        "# embed_dim: Dimensão da sequência de input \n",
        "# dense_dim: Número de nós da camada Dense\n",
        "# num_heads: Número de attention heads\n",
        "\n",
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "\n",
        "        super().__init__(**kwargs)\n",
        "        \n",
        "        self.embed_dim = embed_dim\n",
        "        \n",
        "        self.dense_dim = dense_dim\n",
        "        \n",
        "        self.num_heads = num_heads\n",
        "        \n",
        "        self.attention = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "\n",
        "        self.dense_proj = keras.Sequential([layers.Dense(dense_dim, activation=\"relu\"), layers.Dense(embed_dim),])\n",
        "        \n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        \n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        \n",
        "        if mask is not None:\n",
        "            mask = mask[:, tf.newaxis, :]\n",
        "        \n",
        "        attention_output = self.attention(inputs, inputs, attention_mask=mask)\n",
        "\n",
        "        proj_input = self.layernorm_1(inputs + attention_output)\n",
        "        \n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "        \n",
        "        return self.layernorm_2(proj_input + proj_output)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        \n",
        "        config.update({\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"dense_dim\": self.dense_dim,\n",
        "        })\n",
        "        \n",
        "        return config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "1jFFDfMoQdER"
      },
      "outputs": [],
      "source": [
        "# Criação da classe que modela o Decoder \n",
        "\n",
        "# Na criação do objeto recebe \n",
        "# embed_dim: Dimensão da sequência de input \n",
        "# dense_dim: Número de nós da camada Dense\n",
        "# num_heads: Número de attention heads\n",
        "\n",
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        \n",
        "        super().__init__(**kwargs)\n",
        "        \n",
        "        self.embed_dim = embed_dim\n",
        "        \n",
        "        self.dense_dim = dense_dim\n",
        "        \n",
        "        self.num_heads = num_heads\n",
        "        \n",
        "        self.attention_1 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        \n",
        "        self.attention_2 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "\n",
        "        self.dense_proj = keras.Sequential([layers.Dense(dense_dim, activation=\"relu\"), layers.Dense(embed_dim),])\n",
        "        \n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        \n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        \n",
        "        self.layernorm_3 = layers.LayerNormalization()\n",
        "        \n",
        "        self.supports_masking = True\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        \n",
        "        config.update({\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"dense_dim\": self.dense_dim,\n",
        "        })\n",
        "        \n",
        "        return config\n",
        "\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        \n",
        "        input_shape = tf.shape(inputs)\n",
        "        \n",
        "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "        \n",
        "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
        "        \n",
        "        j = tf.range(sequence_length)\n",
        "        \n",
        "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
        "        \n",
        "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
        "        \n",
        "        mult = tf.concat([tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)], axis=0)\n",
        "        \n",
        "        return tf.tile(mask, mult)\n",
        "\n",
        "    def call(self, inputs, encoder_outputs, mask=None):\n",
        "        \n",
        "        causal_mask = self.get_causal_attention_mask(inputs)\n",
        "        \n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n",
        "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
        "        \n",
        "        attention_output_1 = self.attention_1(\n",
        "            query=inputs,\n",
        "            value=inputs,\n",
        "            key=inputs,\n",
        "            attention_mask=causal_mask)\n",
        "        \n",
        "        attention_output_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "        \n",
        "        attention_output_2 = self.attention_2(\n",
        "            query=attention_output_1,\n",
        "            value=encoder_outputs,\n",
        "            key=encoder_outputs,\n",
        "            attention_mask=padding_mask)\n",
        "        \n",
        "        attention_output_2 = self.layernorm_2(attention_output_1 + attention_output_2)\n",
        "\n",
        "        proj_output = self.dense_proj(attention_output_2)\n",
        "        \n",
        "        return self.layernorm_3(attention_output_2 + proj_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "4jfXOf3nTMOl"
      },
      "outputs": [],
      "source": [
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, input_dim, output_dim, wordEmbedding=None, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        if( wordEmbedding is not None ):\n",
        "            self.token_embeddings = wordEmbedding\n",
        "        else:\n",
        "            self.token_embeddings = layers.Embedding(input_dim=input_dim, output_dim=output_dim)\n",
        "        \n",
        "        self.position_embeddings = layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=output_dim)\n",
        "        \n",
        "        self.sequence_length = sequence_length\n",
        "        \n",
        "        self.input_dim = input_dim\n",
        "        \n",
        "        self.output_dim = output_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \n",
        "        length = tf.shape(inputs)[-1]\n",
        "        \n",
        "        positions = tf.range(start=0, limit=length, delta=1)\n",
        "        \n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        \n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        \n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return tf.math.not_equal(inputs, 0)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(PositionalEmbedding, self).get_config()\n",
        "\n",
        "        config.update({\n",
        "            \"output_dim\": self.output_dim,\n",
        "            \"sequence_length\": self.sequence_length,\n",
        "            \"input_dim\": self.input_dim,\n",
        "        })\n",
        "\n",
        "        return config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "JW_VGzs1TPcZ"
      },
      "outputs": [],
      "source": [
        "# The complete Transformer\n",
        "\n",
        "import keras\n",
        "\n",
        "# Settings \n",
        "\n",
        "#embed_dim = 256\n",
        "embed_dim = 50\n",
        "dense_dim = 2048\n",
        "num_heads = 8\n",
        "\n",
        "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"english\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim, en_embedding_layer)(encoder_inputs)\n",
        "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
        "\n",
        "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"portuguese\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
        "x = TransformerDecoder(embed_dim, dense_dim, num_heads)(x, encoder_outputs)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "\n",
        "transformer = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "transformer.compile(\n",
        "    optimizer=\"rmsprop\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "FdhUT_gqTX8w"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "2201/2201 [==============================] - 74s 33ms/step - loss: 3.1116 - accuracy: 0.2179 - val_loss: 2.7219 - val_accuracy: 0.2796\n",
            "Epoch 2/50\n",
            "2201/2201 [==============================] - 69s 31ms/step - loss: 2.8114 - accuracy: 0.2839 - val_loss: 2.5451 - val_accuracy: 0.3246\n",
            "Epoch 3/50\n",
            "2201/2201 [==============================] - 69s 31ms/step - loss: 2.6500 - accuracy: 0.3196 - val_loss: 2.4045 - val_accuracy: 0.3565\n",
            "Epoch 4/50\n",
            "2201/2201 [==============================] - 69s 31ms/step - loss: 2.5247 - accuracy: 0.3471 - val_loss: 2.3219 - val_accuracy: 0.3819\n",
            "Epoch 5/50\n",
            "2201/2201 [==============================] - 69s 31ms/step - loss: 2.5029 - accuracy: 0.3671 - val_loss: 2.3495 - val_accuracy: 0.3943\n",
            "Epoch 6/50\n",
            "2201/2201 [==============================] - 68s 31ms/step - loss: 2.5150 - accuracy: 0.3833 - val_loss: 2.3652 - val_accuracy: 0.4047\n",
            "Epoch 7/50\n",
            "2201/2201 [==============================] - 69s 31ms/step - loss: 2.5051 - accuracy: 0.3956 - val_loss: 2.3671 - val_accuracy: 0.4112\n",
            "Epoch 8/50\n",
            "2201/2201 [==============================] - 69s 32ms/step - loss: 2.4884 - accuracy: 0.4065 - val_loss: 2.3567 - val_accuracy: 0.4176\n",
            "Epoch 9/50\n",
            "2201/2201 [==============================] - 69s 31ms/step - loss: 2.4711 - accuracy: 0.4153 - val_loss: 2.3510 - val_accuracy: 0.4235\n",
            "Epoch 10/50\n",
            " 679/2201 [========>.....................] - ETA: 42s - loss: 2.4587 - accuracy: 0.4207"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\cm-sa\\Documents\\mestrado\\1_ano\\Análise de Dados\\tp2\\part1_transformer.ipynb Cell 19'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/cm-sa/Documents/mestrado/1_ano/An%C3%A1lise%20de%20Dados/tp2/part1_transformer.ipynb#ch0000019?line=0'>1</a>\u001b[0m transformer\u001b[39m.\u001b[39;49mfit(train_ds, epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49mval_ds)\n",
            "File \u001b[1;32mc:\\Users\\cm-sa\\.conda\\envs\\tfgpu-clone\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32mc:\\Users\\cm-sa\\.conda\\envs\\tfgpu-clone\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
            "File \u001b[1;32mc:\\Users\\cm-sa\\.conda\\envs\\tfgpu-clone\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32mc:\\Users\\cm-sa\\.conda\\envs\\tfgpu-clone\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
            "File \u001b[1;32mc:\\Users\\cm-sa\\.conda\\envs\\tfgpu-clone\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
            "File \u001b[1;32mc:\\Users\\cm-sa\\.conda\\envs\\tfgpu-clone\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
            "File \u001b[1;32mc:\\Users\\cm-sa\\.conda\\envs\\tfgpu-clone\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
            "File \u001b[1;32mc:\\Users\\cm-sa\\.conda\\envs\\tfgpu-clone\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
            "File \u001b[1;32mc:\\Users\\cm-sa\\.conda\\envs\\tfgpu-clone\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "transformer.fit(train_ds, epochs=50, validation_data=val_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_h6nkceEYpUH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-\n",
            "trialforce source org\n",
            "[start] überlegungen zu vereinfachen [end]\n",
            "-\n",
            "the name used to refer to the role or title of position in any user interface pages, for example, western sales vp.\n",
            "[start] der name des dass das bzw die version des benutzers\n",
            "-\n",
            "in the field provided, create an apex class and method.\n",
            "[start] in der offline die folgende informationen in der folgenden schritte\n",
            "-\n",
            "assign service analytics permission sets to users\n",
            "[start] zuweisen von daten für neue benutzer mit dem benutzer enthalten\n",
            "-\n",
            "blng__billedtax__c\n",
            "[start] deaktiviert [end]\n",
            "-\n",
            "think about which variables can relate, describe, or influence the numeric outcome. in our sales example, potential influencer variables include discount, days between lead received and last contacted, lead source, region, vertical, competitor, and promotion. when selecting predictor variables, you want to gather a maximum amount of information from a minimum number of variables. einstein discovery helps this process by eliminating variables that do not have good explanatory power from the story it generates.\n",
            "[start] gutschrift im abschnitt aktionen und aktiviert steht [end]\n",
            "-\n",
            "flow_start_interview_begin\n",
            "[start] deaktiviert [end]\n",
            "-\n",
            "price name\n",
            "[start] [end]\n",
            "-\n",
            "if you've set up entitlement templates, you can associate an entitlement process with a template so all entitlements created using that template automatically use the selected entitlement process.\n",
            "[start] wenn sie die option stellen sie sich für anstelle von\n",
            "-\n",
            "optionally, \"import personal contacts\"\n",
            "[start] verwenden von feldern entfernen von benutzerdefinierten feldern [end]\n",
            "-\n",
            "from lightning experience, you can assign an email application pane to multiple user profiles by clicking set page assignments.\n",
            "[start] um für experience von profilen die innerhalb einer site erstellt\n",
            "-\n",
            "transferring files\n",
            "[start] einstellung von dateien [end]\n",
            "-\n",
            "view details about each partition.\n",
            "[start] anzeigen des benutzerdefinierten des benutzers [end]\n",
            "-\n",
            "from the pages menu in community builder, select record detail or your custom record detail page.\n",
            "[start] wechseln sie auf der seite auswählen in der seite auswählen\n",
            "-\n",
            "date kyc approved/rejected becomes today\n",
            "[start] name des suchfelds von rollen [end]\n",
            "-\n",
            "preview website pages\n",
            "[start] englisch  ist anzeigen [end]\n",
            "-\n",
            "np\n",
            "[start] deaktiviert [end]\n",
            "-\n",
            "click attach file, add quotes and other documents one at a time, and then send.\n",
            "[start] klicken sie komponenten auf senden und felder sie zu erstellen\n",
            "-\n",
            "complete dashboards can be downloaded only as images.\n",
            "[start] stellen sie können für benutzer datensätze an datensätze erstellt wurden\n",
            "-\n",
            "prepare your org for the field service lightning android app. create permission set licenses for your mobile workforce, and install the managed package to support push notifications.\n",
            "[start] aktualisieren sie sich für neue dass accounts und die mobile\n"
          ]
        }
      ],
      "source": [
        "# Testar o desempenho do Transformer em frases do conjunto de teste\n",
        "\n",
        "\n",
        "pt_vocab = target_vectorization.get_vocabulary()\n",
        "pt_index_lookup = dict(zip(range(len(pt_vocab)), pt_vocab))\n",
        "max_decoded_sentence_length = 10\n",
        "\n",
        "def decode_sequence(input_sentence):\n",
        "   \n",
        "    tokenized_input_sentence = source_vectorization([input_sentence])\n",
        "   \n",
        "    decoded_sentence = \"[start]\"\n",
        "   \n",
        "    for i in range(max_decoded_sentence_length):\n",
        "        tokenized_target_sentence = target_vectorization([decoded_sentence])[:, :-1]\n",
        "        \n",
        "        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\n",
        "\n",
        "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
        "        \n",
        "        sampled_token = pt_index_lookup[sampled_token_index]\n",
        "        \n",
        "        decoded_sentence += \" \" + sampled_token\n",
        "        \n",
        "        if sampled_token == \"[end]\":\n",
        "            break\n",
        "    \n",
        "    return decoded_sentence\n",
        "\n",
        "test_eng_texts = [pair[0] for pair in test_pairs]\n",
        "\n",
        "for _ in range(20):\n",
        "    input_sentence = random.choice(test_eng_texts)\n",
        "    print(\"-\")\n",
        "    print(input_sentence)\n",
        "    print(decode_sequence(input_sentence))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UONQEruoZIyh"
      },
      "outputs": [],
      "source": [
        "#for _ in range(5):\n",
        "#    input_sentence = input()\n",
        "#    print(\"-\")\n",
        "#    print(input_sentence)\n",
        "#    print(decode_sequence(input_sentence), '\\n')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "AD2122_Aula9_Transformer_ENG-PT.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 ('tfgpu-clone')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "9517802f9e486875bd1a90cb9316150f9c80975204a62a359dc8ac0c901cd1ea"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
